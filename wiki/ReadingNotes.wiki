#summary Reading Notes读书笔记.
#labels Phase-Implementation
<wiki:toc max_depth="3" />

= Programming Game AI by Example =

== The Steering Behaviors ==

  * _Seek_: The seek steering behavior returns a force that directs an agent toward a target position.
  * _Flee_: Flee is the opposite of seek. Instead of producing a steering force to steer the agent toward a target position, flee creates a force that steers the agent away.
  * _Arrive_: Arrive is a behavior that steers the agent in such a way it decelerates onto the target position.
  * _Pursuit_: Pursuit behavior is useful when an agent is required to intercept a moving target.
  * _Evade_: Evade is almost the same as pursuit except that this time the evader flees from the estimated future position.
  * _Wander_: It's designed to produce a steering force that will give the impression of a random walk through the agent's environment.
  * _Obstacle Avoidance_: Obstacle avoidance is a behavior that steers a vehicle to avoid obstacles lying in its path.
  * _Wall Avoidance_: A wall is a line segment (in 3D, a polygon) with a normal pointing in the direction it is facing. Wall avoidance steers to avoid potential collisions with a wall. It does this by projecting three "feelers" out in front of the vehicle and testing to see if any of them intersect with any walls in the game world.
  * _Interpose_: Interpose returns a steering force that moves a vehicle to the midpoint of the imaginary line connecting two other agents (or points in space, or of an agent and a point).
  * _Hide_: Hide attempts to position a vehicle so that an obstacle is always between itself and the agent — the hunter — it's trying to hide from. You can use this behavior not only for situations where you require an NPC to hide from the player — like find cover when fired at — but also in situations where you would like an NPC to sneak up on a player.
  * _Path Following_: Path following creates a steering force that moves a vehicle along a series of waypoints forming a path. Sometimes paths have a start and end point, and other times they loop back around on themselves forming a never-ending, closed path.
  * _Offset Pursuit_: Offset pursuit calculates the steering force required to keep a vehicle positioned at a specified offset from a target vehicle. This is particularly useful for creating formations. 
  * _Group Behaviors_: Group behaviors are steering behaviors that take into consideration some or all of the other vehicles in the game world. To determine the steering force for a group behavior, a vehicle will consider all other vehicles within a
circular area of predefined size — known as the neighborhood radius — centered on the vehicle.
  * _Separation_: Separation creates a force that steers a vehicle away from those in its neighborhood region. When applied to a number of vehicles, they will spread out, trying to maximize their distance from every other vehicle. 
  * _Alignment_: Alignment attempts to keep a vehicle's heading aligned with its neighbors. The force is calculated by first iterating through all the neighbors and averaging their heading vectors. This value is the desired heading, so we just subtract the vehicle's heading to get the steering force.
  * _Cohesion_: Cohesion produces a steering force that moves a vehicle toward the center of mass of its neighbors. Use this force to keep a group of vehicles together.
  * _Flocking_: Flocking is a beautiful demonstration of what has become known as emergent behavior. Emergent behavior is behavior that looks complex and/or purposeful to the observer but is actually derived spontaneously from fairly simple rules. The lower-level entities following the rules have no idea of the bigger picture; they are only aware of themselves and maybe a few of their neighbors. Flocking is a combination of the three previously described group behaviors: separation, alignment, and cohesion.

== The movement of an autonomous agent ==

The movement of an autonomous agent can be broken down into three layers:
  * Action Selection: This is the part of the agent's behavior responsible for choosing its goals and deciding what plan to follow. It is the part that says "go here" and "do A, B, and then C."
  * This layer is responsible for calculating the desired trajectories required to satisfy the goals and plans set by the action selection layer. 
  * Locomotion: The bottom layer, locomotion, represents the more mechanical aspects of an agent's movement. It is the how of traveling from A to B.

== Tiered AI ==

This type of AI is used in all sorts of computer games. You will often find tiered AI in real-time strategy (RTS) games where the enemy AI is commonly implemented in several layers
at, say, the unit, troop, and commander levels.

== Navigation Graph ==

  * _Points of Visibility_: A points of visibility (POV) navigation graph is created by placing graph nodes, usually by hand, at important points in the environment such that each graph node has line of sight to at least one other. Positioned carefully, the graph nodes will make a graph connecting all the important areas in the world geometry.
  * _Expanded Geometry_: If a game environment is constructed from polygons it's possible to use the information present in those shapes to automatically create a POV graph, which, for large maps can be a real time-saver. This is achieved by first expanding the polygons by an amount proportional to the bounding radius of the game agents.
  * _NavMesh_: One approach growing in popularity with game developers is to use a network of convex polygons, called a navmesh, to describe the walkable areas of a game environment. A convex polygon has the valuable property that it allows unobstructed travel from any point in the polygon to any other. This is useful because it enables an environment to be represented using a graph where each node represents a convex space (instead of a point).

== Goal-Driven Agent Behavior ==

Instead of a finite state machine-based architecture, an agent's behavior is defined as a collection of hierarchical goals. Goals are either atomic or composite in nature. Atomic goals define a single task, behavior, or action, such as seek to position or reload weapon, whereas composite goals are comprised of several subgoals, which in turn
may be either atomic or composite, thereby defining a nested hierarchy. Composites usually describe more complex tasks than their atomic brethren such as build weapons factory or retreat and find cover. Both types of goals are able to monitor their status and have the capability to replan if they fail.

This hierarchical architecture provides the AI programmer with an intuitive mechanism for defining agent behavior because it shares many similarities with the human thought process. Humans select high-level abstract goals based upon their needs and desires and then recursively decompose them into a plan of action that can be followed.

One great thing about a hierarchical goal-based arbitration design is that extra features are provided with little additional effort from the programmer. Personality is one good example. Because the desirability scores are constrained to the same range, it's a simple matter to create agents with different personality traits by multiplying each score with a constant that biases it in the required direction.

The stack-like (LIFO) nature of composite goals automatically endows agents with a memory, enabling them to temporarily change behavior by pushing a new goal (or goals) onto the front of the current goal's subgoal list. As soon as the new goal is satisfied it will popped from the list and the agent will resume whatever it was doing previously. This is a very powerful feature that can be exploited in many different ways. For example:
Automatic Resuming of Interrupted Activities, Negotiating Special Path Obstacles, Command Queuing, and Using the Queue to Script Behavior.

== Fuzzy Logic ==

Fuzzy logic, invented by a man named _Lotfi Zadeh_ in the mid-sixties, enables a computer to reason about linguistic terms and rules in a way similar to humans. Concepts like "far" or "slightly" are not represented by discrete intervals, but by fuzzy sets, enabling values to be assigned to sets to a matter of a degree — a process called fuzzification. Using fuzzified values computers are able to interpret linguistic rules and produce an output that may remain fuzzy or — more commonly, especially in video games — can be defuzzified to provide a crisp value. This is known as fuzzy rule-based inference, and is one of the most popular uses of fuzzy logic.

{{{
fuzzification -> fuzzy rules -> defuzzification
}}}

One major problem with fuzzy inference systems is that as the complexity of the problem increases, the number of rules required escalates at an alarming rate. In 1997 Combs proposed a system that enables the number of rules to grow linearly with the number of member sets instead of exponentially. A rule base can be defined that contains only one rule per consequent member set. One of the drawbacks with this method is that the changes to the rule base required to accommodate the logic are not intuitive. 